package main

import (
	"bytes"
	"context"
	"crypto/rand"
	"encoding/base64"
	"encoding/binary"
	"errors"
	"fmt"
	"io/fs"
	"log"
	"os"
	"os/exec"
	"path/filepath"
	"sort"
	"strings"
	"syscall"
	"time"

	"github.com/cilium/ebpf"
	"github.com/cilium/ebpf/link"
	"github.com/cilium/ebpf/ringbuf"
	"github.com/cilium/ebpf/rlimit"
	"github.com/containerd/containerd/v2/cio"
	containerd "github.com/containerd/containerd/v2/client"
	"github.com/containerd/containerd/v2/mount"
	"github.com/containerd/containerd/v2/namespaces"
	"github.com/containerd/containerd/v2/oci"
	"github.com/containerd/containerd/v2/pkg/cleanup"
	cfs "github.com/containerd/continuity/fs"
	"github.com/samber/lo"
	"golang.org/x/sys/unix"
)

//go:generate go run github.com/cilium/ebpf/cmd/bpf2go -target amd64 -type event bpf ./ebpf/kprobe.c

func uniquePart() string {
	t := time.Now()
	var b [3]byte
	// Ignore read failures, just decreases uniqueness
	rand.Read(b[:])
	return fmt.Sprintf("%d-%s", t.Nanosecond(), base64.URLEncoding.EncodeToString(b[:]))
}

type Config struct {
	runCmd               string
	initCmd              string
	execCmd              string
	extraVolumes         []string
	extraVolumeNotCreate map[string]string
}

type Range struct {
	start uint64
	end   uint64
}

type RangeList []Range

type UsageRecord struct {
	size    int64
	path    string
	records RangeList
}

func (u UsageRecord) Usage() uint64 {
	records := u.records
	sort.Slice(records, func(i, j int) bool {
		a, b := records[i], records[j]
		if a.start == b.start {
			return a.end < b.end
		}
		return a.start < b.start
	})

	allLen := uint64(0)
	currentS, currentE := uint64(0), uint64(0)
	for _, r := range records {
		s, e := r.start, r.end
		switch {
		case s > currentE:
			if currentE > currentS {
				allLen += (currentE - currentS + 1)
			}
			currentS, currentE = s, e

		case s <= currentE:
			if e > currentE {
				currentE = e
			}
		}
	}

	if currentE == 0 {
		return 0
	}

	allLen += (currentE - currentS + 1)

	return allLen
}

func loadEBPF(stopChan <-chan struct{}, continueChan chan<- struct{}, inoUsageMap map[uint64]UsageRecord) {

	// Allow the current process to lock memory for eBPF resources.
	if err := rlimit.RemoveMemlock(); err != nil {
		log.Fatal(err)
	}

	// Load pre-compiled programs and maps into the kernel.
	objs := bpfObjects{}
	if err := loadBpfObjects(&objs, nil); err != nil {
		log.Fatalf("loading objects: %v", err)
	}
	defer objs.Close()

	kprobeFnMap := map[string]struct {
		kprobe    *ebpf.Program
		kretprobe *ebpf.Program
	}{
		"kernel_read": {
			kprobe:    objs.KernelRead,
			kretprobe: objs.KernelReadRet,
		},
		"vfs_read": {
			kprobe:    objs.VfsRead,
			kretprobe: objs.VfsReadRet,
		},
		"vfs_readv": {
			kprobe:    objs.VfsReadv,
			kretprobe: objs.VfsReadvRet,
		},
		"vfs_iter_read": {
			kprobe:    objs.VfsIterRead,
			kretprobe: objs.VfsIterReadRet,
		},
		"kernel_write": {
			kprobe: objs.KernelWrite,
		},
		"vfs_write": {
			kprobe: objs.VfsWrite,
		},
		"vfs_writev": {
			kprobe: objs.VfsWritev,
		},
		"vfs_iter_write": {
			kprobe: objs.VfsIterWrite,
		},
	}

	for fn, prog := range kprobeFnMap {
		// Open a Kprobe at the entry point of the kernel function and attach the
		// pre-compiled program. Each time the kernel function enters, the program
		// will emit an event containing pid and command of the execved task.
		kp, err := link.Kprobe(fn, prog.kprobe, nil)
		if err != nil {
			log.Fatalf("opening kprobe: %s", err)
		}
		defer kp.Close()

		if prog.kretprobe != nil {
			kretp, err := link.Kretprobe(fn, prog.kretprobe, nil)
			if err != nil {
				log.Fatalf("opening kretprobe: %s", err)
			}
			defer kretp.Close()
		}
	}

	// Open a ringbuf reader from userspace RINGBUF map described in the
	// eBPF C program.
	rd, err := ringbuf.NewReader(objs.Events)
	if err != nil {
		log.Fatalf("opening ringbuf reader: %s", err)
	}
	defer rd.Close()

	// Close the reader when the process receives a signal, which will exit
	// the read loop.
	go func() {
		<-stopChan

		if err := rd.Close(); err != nil {
			log.Fatalf("closing ringbuf reader: %s", err)
		}
	}()

	log.Println("Waiting for events..")
	continueChan <- struct{}{}

	// bpfEvent is generated by bpf2go.
	var event bpfEvent
	for {
		record, err := rd.Read()
		if err != nil {
			if errors.Is(err, ringbuf.ErrClosed) {
				log.Println("Received signal, exiting..")
				break
			}
			log.Printf("reading from reader: %s", err)
			continue
		}

		// Parse the ringbuf event entry into a bpfEvent structure.
		if err := binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &event); err != nil {
			log.Printf("parsing ringbuf event: %s", err)
			continue
		}

		if event.Ret == 0 && !event.IsWrite {
			continue
		}

		usageRecord, ok := inoUsageMap[event.Inode]
		if !ok {
			continue
		}

		r := Range{start: uint64(event.Pos), end: uint64(event.Pos) + uint64(event.Ret)}
		if event.IsWrite {
			r = Range{start: uint64(0), end: uint64(usageRecord.size) - 1}
		}

		usageRecord.records = append(usageRecord.records, r)

		inoUsageMap[event.Inode] = usageRecord

		comm := unix.ByteSliceToString(event.Comm[:])
		log.Printf("pid: %d\t\tcomm: %s\tinode: %d\tpos: %d\tret: %d\tused: %d\tfullsize: %d\tisWrite: %v\n", event.Pid, comm, event.Inode, event.Pos, event.Ret, r.end-r.start+1, usageRecord.size, event.IsWrite)
	}

	allUsed, allSize := uint64(0), uint64(0)
	for ino, usageRecord := range inoUsageMap {
		allSize += uint64(usageRecord.size)
		usage := usageRecord.Usage()
		allUsed += usage
		fmt.Println(ino, usageRecord.path, float64(usage)/float64(usageRecord.size))
	}
	fmt.Println(allUsed, allSize, float64(allUsed)/float64(allSize))
}

func execCmdInContainer(ctx context.Context, container containerd.Container, spec *oci.Spec, execCmd string) {
	// 获得容器的任务，用于执行命令
	task, err := container.Task(ctx, nil)
	if err != nil {
		log.Fatal(err)
	}

	// 准备执行的命令和参数
	execID := "some-id"

	// 准备标准输入输出
	cioOpts := cio.NewCreator(cio.WithStdio)

	pspec := spec.Process
	pspec.Args = []string{"bash", "-c", execCmd}

	// 在容器中创建一个新的进程并附加标准输入输出
	process, err := task.Exec(ctx, execID, pspec, cioOpts)
	if err != nil {
		log.Fatal(err)
	}

	// 启动这个进程
	if err := process.Start(ctx); err != nil {
		log.Fatal(err)
	}

	// 等待进程结束
	statusC, err := process.Wait(ctx)
	if err != nil {
		log.Fatal(err)
	}

	// 输出进程的退出状态
	status := <-statusC
	code, _, err := status.Result()
	if err != nil {
		log.Fatal(err)
	}

	log.Printf("Process exited with status code %d", code)

	// 清理进程资源
	exitStatus, err := process.Delete(ctx)
	if err != nil {
		log.Fatal(err)
	}

	if exitStatus.Error() != nil || exitStatus.ExitCode() != 0 {
		log.Fatalf("exit with %#v when exec %s", exitStatus, execCmd)
	}
}

func layerDiff(ctx context.Context, client *containerd.Client, container containerd.Container) []string {
	c, err := client.ContainerService().Get(ctx, container.ID())
	if err != nil {
		panic(err)
	}

	sn := client.SnapshotService(c.Snapshotter)
	info, err := sn.Stat(ctx, c.SnapshotKey)
	if err != nil {
		panic(err)
	}

	lowerKey := fmt.Sprintf("%s-parent-view-%s", info.Parent, uniquePart())
	lower, err := sn.View(ctx, lowerKey, info.Parent)
	if err != nil {
		panic(err)
	}
	defer cleanup.Do(ctx, func(ctx context.Context) {
		sn.Remove(ctx, lowerKey)
	})

	root, err := sn.Mounts(ctx, c.SnapshotKey)
	if err != nil {
		panic(err)
	}

	pathList := make([]string, 0)

	handleChange := func(k cfs.ChangeKind, p string, f os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if k == cfs.ChangeKindDelete || k == cfs.ChangeKindUnmodified ||
			!f.Mode().IsRegular() {
			return nil
		}

		name := p
		if strings.HasPrefix(name, string(filepath.Separator)) {
			name, err = filepath.Rel(string(filepath.Separator), name)
			if err != nil {
				panic(fmt.Errorf("failed to make path relative: %w", err))
			}
		}
		// Canonicalize to POSIX-style paths using forward slashes. Directory
		// entries must end with a slash.
		name = filepath.ToSlash(name)
		if f.IsDir() && !strings.HasSuffix(name, "/") {
			name += "/"
		}
		fullPath := fmt.Sprintf(
			"/run/containerd/io.containerd.runtime.v2.task/default/%s/rootfs/%s",
			container.ID(),
			name,
		)
		pathList = append(pathList, fullPath)

		return nil
	}

	if err := mount.WithTempMount(ctx, lower, func(lowerRoot string) error {
		return mount.WithReadonlyTempMount(ctx, root, func(upperRoot string) error {
			return cfs.Changes(ctx, lowerRoot, upperRoot, handleChange)
		})
	}); err != nil {
		panic(err)
	}

	return pathList
}

func runAndMonitor(conf *Config) {
	// TODO use containerd library to run container
	extraLoaclPaths := []string{}
	notDelete := map[string]bool{}
	mountStr := ""
	for _, volume := range conf.extraVolumes {
		if localPath, ok := conf.extraVolumeNotCreate[volume]; ok {
			extraLoaclPaths = append(extraLoaclPaths, localPath)
			notDelete[localPath] = true
			continue
		}
		dir, err := os.MkdirTemp("/root/morv", "")
		if err != nil {
			panic(err)
		}
		dir, err = filepath.Abs(dir)
		if err != nil {
			panic(err)
		}
		extraLoaclPaths = append(extraLoaclPaths, dir)
		mountStr += fmt.Sprintf("-v %s:%s ", dir, volume)
	}
	cmd := exec.Command("bash", "-c", fmt.Sprintf("nerdctl run %s %s", mountStr, conf.runCmd))
	containerIDBytes, err := cmd.CombinedOutput()
	if err != nil {
		panic(err)
	}
	containerID := string(containerIDBytes)
	containerID = strings.TrimSuffix(containerID, "\n")
	defer func(containerID string) {
		cmd := exec.Command("bash", "-c", fmt.Sprintf("nerdctl -n default rm -f %s", containerID))
		output, err := cmd.CombinedOutput()
		if err != nil {
			panic(string(output) + " " + err.Error())
		}
		for _, path := range extraLoaclPaths {
			if notDelete[path] {
				continue
			}
			os.RemoveAll(path)
		}
	}(containerID)
	log.Printf("start container %s\n", containerID)

	// 创建新的客户端，假设 containerd 的 socket 文件在默认的位置
	client, err := containerd.New("/run/containerd/containerd.sock")
	if err != nil {
		log.Fatal(err)
	}
	defer client.Close()

	// 创建一个新的上下文对象
	ctx := namespaces.WithNamespace(context.Background(), "default")

	// 通过容器的ID或名字获取容器对象
	container, err := client.LoadContainer(ctx, containerID)
	if err != nil {
		log.Fatal(err)
	}

	spec, err := container.Spec(ctx)
	if err != nil {
		panic(err)
	}

	execCmdInContainer(ctx, container, spec, conf.initCmd)

	pathList := layerDiff(ctx, client, container)

	for _, path := range extraLoaclPaths {
		filepath.Walk(path, func(path string, info fs.FileInfo, err error) error {
			if info.Mode().IsRegular() {
				pathList = append(pathList, path)
			}
			return nil
		})
	}

	fmt.Printf("%s\n", pathList)

	inoUsageMap := make(map[uint64]UsageRecord, len(pathList))

	lo.ForEach(pathList, func(path string, _ int) {
		fileInfo, err := os.Stat(path)
		if err != nil {
			if os.IsNotExist(err) {
				log.Printf("file not exist %s", path)
				return
			}
			panic(err)
		}
		stat, ok := fileInfo.Sys().(*syscall.Stat_t)
		if !ok {
			log.Fatalf("not a unix.Stat_t %s", path)
		}

		inoUsageMap[stat.Ino] = UsageRecord{
			size:    stat.Size,
			path:    path,
			records: make(RangeList, 0),
		}
	})

	continueChan := make(chan struct{})
	stopChan := make(chan struct{})

	go func() {
		loadEBPF(stopChan, continueChan, inoUsageMap)
	}()
	defer func() {
		stopChan <- struct{}{}
	}()

	<-continueChan

	execCmdInContainer(ctx, container, spec, conf.execCmd)

	time.Sleep(5 * time.Second)
}

func main() {
	stopChan := make(chan struct{})
	// Allow the current process to lock memory for eBPF resources.
	if err := rlimit.RemoveMemlock(); err != nil {
		log.Fatal(err)
	}

	// Load pre-compiled programs and maps into the kernel.
	objs := bpfObjects{}
	if err := loadBpfObjects(&objs, nil); err != nil {
		log.Fatalf("loading objects: %v", err)
	}
	defer objs.Close()

	kprobeFnMap := map[string]struct {
		kprobe    *ebpf.Program
		kretprobe *ebpf.Program
	}{
		"kernel_read": {
			kprobe:    objs.KernelRead,
			kretprobe: objs.KernelReadRet,
		},
		"vfs_read": {
			kprobe:    objs.VfsRead,
			kretprobe: objs.VfsReadRet,
		},
		"vfs_readv": {
			kprobe:    objs.VfsReadv,
			kretprobe: objs.VfsReadvRet,
		},
		"vfs_iter_read": {
			kprobe:    objs.VfsIterRead,
			kretprobe: objs.VfsIterReadRet,
		},
		"kernel_write": {
			kprobe: objs.KernelWrite,
		},
		"vfs_write": {
			kprobe: objs.VfsWrite,
		},
		"vfs_writev": {
			kprobe: objs.VfsWritev,
		},
		"vfs_iter_write": {
			kprobe: objs.VfsIterWrite,
		},
	}

	for fn, prog := range kprobeFnMap {
		// Open a Kprobe at the entry point of the kernel function and attach the
		// pre-compiled program. Each time the kernel function enters, the program
		// will emit an event containing pid and command of the execved task.
		kp, err := link.Kprobe(fn, prog.kprobe, nil)
		if err != nil {
			log.Fatalf("opening kprobe: %s", err)
		}
		defer kp.Close()

		if prog.kretprobe != nil {
			kretp, err := link.Kretprobe(fn, prog.kretprobe, nil)
			if err != nil {
				log.Fatalf("opening kretprobe: %s", err)
			}
			defer kretp.Close()
		}
	}

	// Open a ringbuf reader from userspace RINGBUF map described in the
	// eBPF C program.
	rd, err := ringbuf.NewReader(objs.Events)
	if err != nil {
		log.Fatalf("opening ringbuf reader: %s", err)
	}
	defer rd.Close()

	// Close the reader when the process receives a signal, which will exit
	// the read loop.
	go func() {
		<-stopChan

		if err := rd.Close(); err != nil {
			log.Fatalf("closing ringbuf reader: %s", err)
		}
	}()

	log.Println("Waiting for events..")

	logFile := "log.txt"
	f, err := os.OpenFile(logFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
	if err != nil {
		panic("open log file failed: " + err.Error())
	}

	// bpfEvent is generated by bpf2go.
	var event bpfEvent
	for {
		record, err := rd.Read()
		if err != nil {
			if errors.Is(err, ringbuf.ErrClosed) {
				log.Println("Received signal, exiting..")
				break
			}
			log.Printf("reading from reader: %s", err)
			continue
		}

		// Parse the ringbuf event entry into a bpfEvent structure.
		if err := binary.Read(bytes.NewBuffer(record.RawSample), binary.LittleEndian, &event); err != nil {
			log.Printf("parsing ringbuf event: %s", err)
			continue
		}

		// if event.IsWrite {
		// 	continue
		// }

		// if event.Ret == 0 && !event.IsWrite {
		// 	continue
		// }

		comm := unix.ByteSliceToString(event.Comm[:])
		if comm == "node" || strings.HasPrefix(comm, "__debug") {
			continue
		}
		filename := unix.ByteSliceToString(event.Name[:])
		logStr := fmt.Sprintf("pid: %d\t\tcomm: %s\tfilename:%s\t,inode: %d\tpos: %d\tret: %d\tisWrite: %v\n", event.Pid, comm, filename, event.Inode, event.Pos, event.Ret, event.IsWrite)
		f.WriteString(logStr)
		if strings.Contains(comm, "criu") {
			log.Printf("pid: %d\t\tcomm: %s\tinode: %d\tpos: %d\tret: %d\tisWrite: %v\n", event.Pid, comm, event.Inode, event.Pos, event.Ret, event.IsWrite)
		}
	}

	defer func() {
		stopChan <- struct{}{}
	}()
}

// func main() {
// 	configList := []*Config{
// 		// {
// 		// 	imageName: "ubuntu",
// 		// 	startCmd:  "sleep inf",
// 		// 	initCmd:   "cp /usr/bin/cat /root/cat",
// 		// 	execCmd:   "/root/cat /etc/passwd",
// 		// },
// 		// {
// 		// 	imageName: "ubuntu",
// 		// 	startCmd:  "sleep inf",
// 		// 	initCmd:   "apt update && apt install neofetch -y",
// 		// 	execCmd:   "apt update && neofetch",
// 		// },
// 		// {
// 		// 	imageName: "ubuntu",
// 		// 	startCmd:  "sleep inf",
// 		// 	initCmd:   "cp /etc/passwd /root/passwd",
// 		// 	execCmd:   "echo kk > /root/passwd",
// 		// },
// 		// {
// 		// 	runCmd:       "-d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:8.3.0",
// 		// 	extraVolumes: []string{"/var/lib/mysql"},
// 		// 	initCmd:      "echo 1",
// 		// 	execCmd:      "echo 1",
// 		// },
// 		// {
// 		// 	runCmd:       "-d -p 27017:27017 mongo:7.0.7",
// 		// 	extraVolumes: []string{"/data/db", "/data/configdb"},
// 		// 	initCmd:      "echo 1",
// 		// 	execCmd:      "echo 1",
// 		// },
// 		// {
// 		// 	runCmd:       "-d ubuntu:22.04 sleep inf",
// 		// 	extraVolumes: []string{},
// 		// 	initCmd:      "apt update && apt-get install build-essential -y",
// 		// 	execCmd:      "apt-get install vim gdb -y",
// 		// },
// 		// {
// 		// 	runCmd:       "-d -v /root/ccr-test/java-test:/root openjdk:23-slim-bullseye sleep inf",
// 		// 	extraVolumes: []string{"/root"},
// 		// 	extraVolumeNotCreate: map[string]string{
// 		// 		"/root": "/root/ccr-test/java-test",
// 		// 	},
// 		// 	initCmd: "echo 1",
// 		// 	execCmd: "echo 1",
// 		// },
// 		// {
// 		// 	runCmd:       "-d -v /root/ccr-test/nodejs-test:/root -p 3000:3000 node:21-bullseye sleep inf",
// 		// 	extraVolumes: []string{"/root"},
// 		// 	extraVolumeNotCreate: map[string]string{
// 		// 		"/root": "/root/ccr-test/nodejs-test",
// 		// 	},
// 		// 	initCmd: "echo 1",
// 		// 	execCmd: "echo 1",
// 		// },
// 		{
// 			runCmd:  "-d -v /root/ccr-test/pytorch-test:/home/ubuntu/pytorch-test armswdev/pytorch-arm-neoverse:r24.02-torch-2.2.0-rc8-openblas sleep inf",
// 			initCmd: "cp /home/ubuntu/pytorch-test/* /home/ubuntu/",
// 			execCmd: "echo 1",
// 		},
// 	}

// 	for _, conf := range configList {
// 		runAndMonitor(conf)
// 	}
// }
